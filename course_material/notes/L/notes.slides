<title>Transactions and Concurrency

<slide>
<heading>Transactions, Concurrency, Recovery
DBMSs provide access to valuable information resources in
an environment that is:
<itemize>
<item> <em>shared</em> - concurrent access by multiple users
<item> <em>unstable</em> - potential for hardware/software failure
</itemize>
Each user should see the system as:
<itemize>
<item> unshared - their work is not inadvertantly affected by others
<item> stable - the data survives in the face of system failures
</itemize>
Goal: data integrity is maintained at all times.
</slide>

<slide>
<continued>
Transaction processing
<itemize>
<item> techniques for describing <q>logical units of work</q>
	in applications in terms of underlying DBMS operations
</itemize>
Concurrency control
<itemize>
<item> techniques for ensuring that multiple concurrent
	transactions do not interfere with each other
</itemize>
Recovery mechanisms
<itemize>
<item> techniques to restore information to a consistent
	state, even after major hardware shutdowns/failures
</itemize>
</slide>

<slide>
<heading>Transaction Processing
A <em>transaction</em> is a <q>logical <em>unit</em> of work</q> in a DB application.
<p>
Examples:
<itemize>
<item> booking an airline or concert ticket
<item> transferring funds between bank accounts
<item> updating stock levels via point-of-sale terminal
<item> enrolling in a course or class
</itemize>
A transaction typically comprises multiple DBMS operations.
<p>
E.g. <~> select ... update ... insert ... select ... insert ...
</slide>

<slide>
<continued>
Transaction processing (TP) systems can be viewed as highly dynamic
database applications.
<p>
Common characteristics of transaction-processing systems:
<itemize>
<item> multiple concurrent updates
	<~> <small>(<$>10<sup>2</sup> .. 10<sup>4</sup></$> operations per second)</small>
<item> real-time response requirement
	<~> <small>(preferably <$><<</$> 1 sec; max 5 secs)</small>
<item> high availability (24 <$><times></$> 7)
	<~> <small>(especially for e.g. ecommerce systems)</small>
</itemize>
<~><br>
TP benchmarks: important measure of DBMS performance.
</slide>

<slide>
<heading>Example Transaction
<b>Problem:</b> transfer funds between two accounts in same bank.
<p>
Possible implementation in PLpgSQL:
<sprogram>
create or replace function
    transfer(src int, dest int, amount float) returns void
as $$
declare
    oldBalance float;
    newBalance float;
begin
    <comment>-- error checking</comment>
    <blue>select * from Accounts where id=src;</blue>
    if (not found) then
        raise exception 'Invalid Withdrawal Account';
    end if;
    <blue>select * from Accounts where id=dest;</blue>
    if (not found) then
        raise exception 'Invalid Deposit Account';
    end if;
...
</sprogram>
</slide>

<slide>
<continued>
<sprogram>
...
    <comment>-- action</comment>
(A) <blue>select balance into oldBalance
    from Accounts where id=src;</blue>
    if (oldBalance < amount) then
        raise exception 'Insufficient funds';
    end if;
    newBalance := oldBalance - amount;
(B) <red>update Accounts
    set    balance := newBalance
    where  id = src;</red>
    <comment>-- partial completion of transaction</comment>
(C) <red>update Accounts
    set    balance := balance + amount
    where  id = dest;</red>
    commit; <comment>-- redundant; function = transaction</comment>
end;
$$ language plpgsql;
</sprogram>
</slide>

<slide>
<continued>
Consider two simultaneous transfers between accounts, e.g.
<itemize>
<sitem> T1 transfers <dollar>200 from account X to account Y
<sitem> T2 transfers <dollar>300 from account X to account Y
</itemize>
<p>
If the sequence of events is like:
<program>
T1:  ...  A  B  C  ...
T2:                ...  A  B  C  ...
</program>
everything works correctly, i.e.
<itemize>
<sitem> overall, account X is reduced by <dollar>500
<sitem> overall, account Y is increased by <dollar>500
</itemize>
</slide>

<slide>
<continued>
What if the sequence of events is like?
<program>
T1:  ...  A   B        C  ...
T2:    ...  A   B   C  ...
</program>
In terms of database operations, this is what happens:
<itemize>
<sitem> T1 gets balance from X (<dollar>A)
<sitem> T2 gets same balance from X (<dollar>A)
<sitem> T1 decrements balance in X (<dollar>A - 200)
<sitem> T2 decrements balance in X (<dollar>A - 300)
<sitem> T2 increments balance in Y (<dollar>B + 300)
<sitem> T1 increments balance in Y (<dollar>B + 300 + 200)
</itemize>
Final balance of Y is ok; final balance of X is wrong.
</slide>

<slide>
<heading>Transaction Concepts
A transaction must always terminate, either:
<itemize>
<item> successfully (<@>COMMIT</@>), with all changes preserved
<item> unsuccessfully (<@>ABORT</@>), with database unchanged
</itemize>
<diagram>Pic/xact/trans-states.png
</slide>

<slide>
<continued>
To describe transaction effects, we consider:
<itemize>
<item> <@>READ</@> - transfer data from disk to memory
<item> <@>WRITE</@> - transfer data from memory to disk
<item> <@>ABORT</@> - terminate transaction, unsuccessfully
<item> <@>COMMIT</@> - terminate transaction, successfully
</itemize>
<~><br>
<@>SELECT</@> produces <@>READ</@> operations on the database.
<p>
<@>INSERT</@>, <@>UPDATE</@>, <@>DELETE</@> produce <@>WRITE</@>/<@>READ</@> operations.
</slide>

<slide>
<continued>
The <@>READ</@>, <@>WRITE</@>, <@>ABORT</@>, <@>COMMIT</@> operations:
<itemize>
<item> occur in the context of some transaction <$>T</$>
<item> involve manipulation of data items <$>X, Y, ...</$>
	<~> <small>(<tt>READ</tt> and <tt>WRITE</tt>)</small>
</itemize>
The operations are typically denoted as:
<deftable>
<row>
<col1> <$>R<sub>T</sub>(X)</$> </col1>
<col2> read item <$>X</$> in transaction <$>T</$> </col2>
</row>
<row>
<col1> <$>W<sub>T</sub>(X)</$> </col1>
<col2> write item <$>X</$> in transaction <$>T</$> </col2>
</row>
<row>
<col1> <$>A<sub>T</sub></$> </col1>
<col2> abort transaction <$>T</$> </col2>
</row>
<row>
<col1> <$>C<sub>T</sub></$> </col1>
<col2> commit transaction <$>T</$> </col2>
</row>
</deftable>
</slide>

<slide>
<continued>
Execution of the above funds transfer example can be described as
<program>
T: READ(S);  READ(D);  <comment>-- S = source tuple, D = dest tuple</comment>
   READ(S);  S.bal := S.bal-amount;  WRITE(S)
   READ(D);  D.bal := D.bal+amount;  WRITE(D)
   COMMIT;
</program>
or simply as
<p>
<center>
<$> R<sub>T</sub>(S) <~> R<sub>T</sub>(D) <~> R<sub>T</sub>(S) <~> W<sub>T</sub>(S) <~> R<sub>T</sub>(D) <~> W<sub>T</sub>(D) <~> C<sub>T</sub> </$>
</center>
<p>
<~><br>
This is known as a <em>schedule</em> for the transaction.
</slide>

<slide>
<heading>Transaction Consistency
Transactions typically have intermediate states
that are inconsistent.
<p>
However, states <em>before</em> and <em>after</em> transaction
must be consistent.
<~><br><~><br>
<diagram>Pic/xact/trans-consis.png
</slide>

<slide>
<heading>ACID Properties
Data integrity is assured if transactions satisfy the following:
<p>
<b><red>A</red></b>tomicity <br>
<small>
<itemize>
<item> Either all operations of transaction are reflected in database
or none are.
</itemize>
</small>
<b><red>C</red></b>onsistency <br>
<small>
<itemize>
<item> Execution of a transaction in isolation preserves data consistency.
</itemize>
</small>
<b><red>I</red></b>solation <br>
<small>
<itemize>
<item> Each transaction is <q>unaware</q> of other transactions executing
concurrently in the system.
</itemize>
</small>
<b><red>D</red></b>urability <br>
<small>
<itemize>
<item> After a transaction completes successfully, its changes persist
even after subsequent system failure.
</itemize>
</small>
</slide>

<slide>
<continued>
<red>A</red>tomicity is handled by the <em>commit</em> and <em>rollback</em> mechanisms.
<itemize>
<item> <b>commit</b> saves all changes and ends the transaction
<item> <b>rollback</b> <i>undoes</i> changes already made by the transaction
</itemize>
<p>
<red>D</red>urability is handled by implementing <em>stable storage</em>, via
<itemize>
<item> redundancy, to deal with hardware failures
<item> logging/checkpoint mechanisms, to recover state
</itemize>
Here, we consider primarily <red>c</red>onsistency and <red>i</red>solation.
</slide>

<slide>
<heading>Transaction Anomalies
If <em>concurrent</em> transactions access <em>shared</em> data objects,
various anomalies can arise.
<p>
We give examples using the following two transactions:
<program>
T1: read(X)           T2: read(X)
    X := X + N            X := X + M
    write(X)              write(X)
    read(Y)
    Y := Y - N
    write(Y)
</program>
and initial DB state <@>X=100</@>, <@>Y=50</@>, <@>N=5</@>, <@>M=8</@>.
</slide>

<slide>
<heading>Serial Schedules
<em>Serial</em> execution means no overlap of transaction operations.
<p>
If <@>T1</@> and <@>T2</@> transactions are executed serially:
<program>
T1: R(X) W(X) R(Y) W(Y)
T2:                     R(X) W(X)
</program>
or
<program>
T1:           R(X) W(X) R(Y) W(Y)
T2: R(X) W(X)
</program>
the database is left in a consistent state.
</slide>

<slide>
<continued>
The basic idea behind serial schedules:
<itemize>
<item> each transaction is correct <br>
	<small>(leaves the database in a consistent state if run to completion individually)</small>
<item> the database starts in a consistent state
<item> the first transaction completes, leaving the DB consistent
<item> the next transaction completes, leaving the DB consistent
</itemize>
As would occur e.g. in a single-user database system.
</slide>

<slide>
<continued>
For the first schedule in our example:
<p>
<program>
Database   T1                   T2
---------  -------------------  --------------
X    Y               X    Y               X
100  50              ?    ?               ?
           read(X)   100
           X:=X+N    105
105        write(X)
           read(Y)        50
           Y:=Y-N         45
     45    write(Y)
                                read(X)   105
                                X:=X+M    113
113                             write(X)
---------
113  45
</program>
</slide>

<slide>
<continued>
For the second schedule in our example:
<p>
<program>
Database   T1                   T2
---------  -------------------  --------------
X    Y               X    Y               X
100  50              ?    ?               ?
                                read(X)   100
                                X:=X+M    108
108                             write(X)
           read(X)   108
           X:=X+N    113
113        write(X)
           read(Y)        50
           Y:=Y-N         45
     45    write(Y)
---------
113  45
</program>
</slide>

<slide>
<continued>
Note that serial execution doesn't mean that each transaction
will get the same results, regardless of the order.
<p>
Consider the following two transactions:
<program>
T1: select sum(salary)
    from Employee where dept='Sales'

T2: insert into Employee
    values (....,'Sales',...)
</program>
If we execute <@>T1</@> then <@>T2</@>,
we get a smaller salary total than if we execute <@>T2</@> then <@>T1</@>.
<p>
In both cases, however, the salary total is <em>consistent</em> with the state
of the database <em>at the time</em> the query is executed.
</slide>

<slide>
<heading>Concurrent Schedules
A serial execution of consistent transactions is always consistent.
<p>
If transactions execute under a concurrent (nonserial) schedule,
the potential exists for conflict among their effects.
<p>
In the worst case, the effect of executing the transactions ...
<itemize>
<item> is to leave the database in an inconsistent state
<item> even though each transaction, by itself, <i>is</i> consistent
</itemize>
So why don't we observe such problems in real DBMSs? ...
<itemize>
<item> <em>concurrency control</em> mechanisms handle them
	<~> <small>(see later)</small>.
</itemize>
</slide>

<slide>
<heading>Valid Concurrent Transaction
Not all concurrent executions cause problems.
<p>
For example, the schedules
<program>
T1: R(X) W(X)           R(Y) W(Y)
T2:           R(X) W(X)
</program>
or
<program>
T1: R(X) W(X)      R(Y)      W(Y)
T2:           R(X)      W(X)
</program>
or ...
<p>
leave the database in a consistent state.
</slide>

<slide>
<heading>Lost Update Problem
Consider the following schedule where the transactions execute in parallel:
<program>
T1: R(X)      W(X) R(Y)      W(Y)
T2:      R(X)           W(X)
</program>
In this scenario:
<itemize>
<item> <@>T2</@> reads data (<@>X</@>) that <@>T1</@> is currently operating on
<item> then makes changes to <@>X</@> and overwrites <@>T1</@>'s result
</itemize>
This is called a <em>Write-Read (WR) Conflict</em> or <em>dirty read</em>. 
<p>
The result: <@>T1</@>'s update to <@>X</@> is lost.
</slide>

<slide>
<continued>
Consider the states in the WR Conflict schedule:
<p>
<program>
Database   T1                   T2
---------  -------------------  --------------
X    Y               X    Y               X
100  50              ?    ?               ?
           read(X)   100
           X:=X+N    105
                                read(X)   100
                                X:=X+M    108
105        write(X)
           read(Y)        50
108                             write(X)
           Y:=Y-N         45
     45    write(Y)
---------
108  45
</program>
</slide>

<slide>
<heading>Temporary Update Problem
Consider the following schedule where one transaction fails:
<program>
T1: R(X) W(X) A
T2:             R(X) W(X)
</program>
Transaction <@>T1</@> aborts after writing <@>X</@>.
<p>
The abort <i>will</i> undo the changes to <@>X</@>,
but where the undo occurs can affect the results.
<p>
Consider three places where undo might occur:
<program>
T1: R(X) W(X) A <green>[1]</green>     <green>[2]</green>     <green>[3]</green>
T2:                 R(X)    W(X)
</program>
</slide>

<slide>
<heading>Temporary Update - Case 1
This scenario is ok. <~> <@>T1</@>'s effects have been eliminated.
<p>
<program>
Database   T1                   T2
---------  -------------------  --------------
X    Y               X    Y               X
100  50              ?    ?               ?
           read(X)   100
           X:=X+N    105
105        write(X)
           abort
100        undo
                                read(X)   100
                                X:=X+M    108
108                             write(X)
---------
108  50
</program>
</slide>

<slide>
<heading>Temporary Update - Case 2
In this scenario, some of <@>T1</@>'s effects have been retained.
<p>
<program>
Database   T1                   T2
---------  -------------------  --------------
X    Y               X    Y               X
100  50              ?    ?               ?
           read(X)   100
           X:=X+N    105
105        write(X)
           abort
                                read(X)   105
                                X:=X+M    113
100        undo
113                             write(X)
---------
113  50
</program>
</slide>

<slide>
<heading>Temporary Update - Case 3
In this scenario, <@>T2</@>'s effects have been lost, even after commit.
<p>
<program>
Database   T1                   T2
---------  -------------------  --------------
X    Y               X    Y               X
100  50              ?    ?               ?
           read(X)   100
           X:=X+N    105
105        write(X)
           abort
                                read(X)   105
                                X:=X+M    113
113                             write(X)
100        undo
---------
100  50
</program>
</slide>

<slide>
<heading>Valid Schedules
For ACID, we must ensure that schedules are:
<itemize>
<item> <em>serializable</em>
<p>
<small>
The effect of executing <$>n</$> concurrent transactions 
is the same as the effect of executing them serially in some order.
<p>
For assessing the correctness of concurrency control methods,
need a test to check whether it produces serializable schedules.
</small>
<item> <em>recoverable</em>
<p>
<small>
A failed transaction should not affect the ability to recover the
system to a consistent state.
<p>
This can be ensured if transactions commit only <em>after</em> all
transactions whose changes they read commit.
</small>
</itemize>
</slide>

<slide>
<heading>Serializability
If a concurrent schedule for transactions <$>T<sub>1</sub> ..T<sub>n</sub></$>
acts like a serial schedule for <$>T<sub>1</sub> ..T<sub>n</sub></$>,
then consistency is guaranteed.
<p>
To determine this requires a notion of <em>schedule equivalence</em>.
<p>
<small>
Note: we are not attempting to determine equivalence of entire
computations, simply of the interleaved sequences of read/write
operations.
</small>
<p>
A <em>serializable schedule</em> is a concurrent schedule that
produces a final state that is the same as that produced by
some serial schedule.
<p>
There are two primary formulations of serializability:
<itemize>
<item> <em>conflict serializibility</em>
	<~> <small>(read/write operations occur in the <q>right</q> order)</small>

<item> <em>view serializibility</em>
	<~> <small>(read operations <i>see</i> the correct version of data)</small>
</itemize>
</slide>

<slide>
<heading>Conflict Serializability
Consider two transactions <$>T<sub>1</sub></$> and <$>T<sub>2</sub></$>
acting on data item <$>X</$>.
<p>
Considering only read/write operations, the possibilities are:
<p>
<center>
<table 5>
<row>
<col1><b><$>T<sub>1</sub></$> first</b></col1>
<col2> <~> </col2>
<col2><b><$>T<sub>2</sub></$> first</b></col2>
<col2> <~> </col2>
<col3>Equiv?</col3>
</row>
<row>
<col1><$>R<sub>1</sub>(X) R<sub>2</sub>(X)</$></col1>
<col2> <~> </col2>
<col2><$>R<sub>2</sub>(X) R<sub>1</sub>(X)</$></col2>
<col2> <~> </col2>
<col3>yes</col3>
</row>
<row>
<col1><$>R<sub>1</sub>(X) W<sub>2</sub>(X)</$></col1>
<col2> <~> </col2>
<col2><$>W<sub>2</sub>(X) R<sub>1</sub>(X)</$></col2>
<col2> <~> </col2>
<col3>no</col3>
</row>
<row>
<col1><$>W<sub>1</sub>(X) R<sub>2</sub>(X)</$></col1>
<col2> <~> </col2>
<col2><$>R<sub>2</sub>(X) W<sub>1</sub>(X)</$></col2>
<col2> <~> </col2>
<col3>no</col3>
</row>
<row>
<col1><$>W<sub>1</sub>(X) W<sub>2</sub>(X)</$></col1>
<col2> <~> </col2>
<col2><$>W<sub>2</sub>(X) W<sub>1</sub>(X)</$></col2>
<col2> <~> </col2>
<col3>no</col3>
</row>
</table>
</center>
<p>
<small>
If <$>T<sub>1</sub></$> and <$>T<sub>2</sub></$> act on different data items,
result is equivalent regardless of order.
</small>
</slide>

<slide>
<continued>
Two transactions have a potential <em>conflict</em> if
<itemize>
<item> they perform operations on the same data item
<item> at least one of the operations is a write operation
</itemize>
In such cases, the order of operations affects the result.
<p>
Conversely, if two operations in a schedule don't conflict, <br>
we can swap their order without affecting the overall result.
<p>
This gives a basis for determining equivalence of schedules.
</slide>

<slide>
<continued>
If we can transform a schedule
<itemize>
<item> by swapping the orders of non-conflicting operations
<item> such that the result is a serial schedule
</itemize>
then we say that the schedule is <em>conflict serializible</em>.
<p>
If a concurrent schedule is equivalent to some (any) serial schedule,
then we have a consistency guarantee.
</slide>

<slide>
<continued>
Example: transform a concurrent schedule to serial schedule
<program>
T1: R(A) W(A)      R(B)      W(B)
T2:           R(A)      W(A)      R(B) W(B)
<red>swap</red>
T1: R(A) W(A) <green>R(B)</green>           W(B)
T2:                <green>R(A)</green> W(A)      R(B) W(B)
<red>swap</red>
T1: R(A) W(A) R(B)      <green>W(B)</green>
T2:                R(A)      <green>W(A)</green> R(B) W(B)
<red>swap</red>
T1: R(A) W(A) R(B) <green>W(B)</green>
T2:                     <green>R(A)</green> W(A) R(B) W(B)
</program>
</slide>

<slide>
<heading>View Serializability
<em>View Serializability</em> is
<itemize>
<item> an alternative formulation of serializability
<item> that is less conservative than conflict serializability (CS) <br>
	<small>(some safe schedules that are view serializable are not conflict serializable)</small>
</itemize>
As with CS, it is based on a notion of schedule equivalence
<itemize>
<item> a schedule is <q>safe</q> if <i>view equivalent</i> to a serial schedule
</itemize>
The idea: if all the read operations in two schedules ...
<itemize>
<item> always read the result of the same write operations
<item> then the schedules must produce the same result
</itemize>
</slide>

<slide>
<continued>
Two schedules <$>S</$> and <$>S'</$> on <$>T<sub>1</sub> .. T<sub>n</sub></$>
are <em>view equivalent</em> iff
<itemize>
<item> for each shared data item <$>X</$>
<itemize>
<item> if <$>T<sub>j</sub></$> reads the initial value of <$>X</$> in <$>S</$>,
	then it also reads the initial value of <$>X</$> in <$>S'</$>
<item> if <$>T<sub>j</sub></$> reads <$>X</$> in <$>S</$> and <$>X</$> was produced by <$>T<sub>k</sub></$>,
then <$>T<sub>j</sub></$> must also read the value of <$>X</$> produced by <$>T<sub>k</sub></$> in <$>S'</$>
<item> if <$>T<sub>j</sub></$> performs the final write of <$>X</$> in <$>S</$>,
then it must also perform the final write of <$>X</$> in <$>S'</$>
</itemize>
</itemize>
<small>
To check serializibilty of <$>S</$>, find a serial schedule that is view equivalent to <$>S</$>
</small>
</slide>

<slide>
<heading>Testing Serializability
In practice, we don't test specific schedules for serializability.
<p>
However, in designing concurrency control schemes, we need a
way of checking whether they produce <q>safe</q> schedules.
<p>
This is typically achieved by a demonstration that the scheme generates only
serializable schedules, and we need a serializability test for this.
<p>
There is a simple and efficient test for conflict serializability; <br>
there is a more complex test for view serializablity.
<p>
Both tests are based on notions of
<itemize>
<item> building a graph to represent transaction interactions
<item> testing properties of this graph <small>(checking for cycles)</small>
</itemize>
</slide>

<slide>
<continued>
A <em>precedence graph</em> <$>G = (V,E)</$> for a schedule <$>S</$> consists of
<itemize>
<item> a vertex in <$>V</$> for each transaction from <$>T<sub>1</sub> .. T<sub>n</sub></$>
<item> an edge in <$>E</$> for each pair <$>T<sub>j</sub></$>
	and <$>T<sub>k</sub></$>, such that
<itemize>
<item> there is a pair of conflicting operations between <$>T<sub>j</sub></$> &amp; <$>T<sub>k</sub></$>
<item> the <$>T<sub>j</sub></$> operation occurs before the <$>T<sub>k</sub></$> operation
</itemize>
</itemize>
Note: the edge is directed from <$>T<sub>j</sub> <~> <rightarrow> <~> T<sub>k</sub></$>
</slide>

<slide>
<continued>
If an edge <$>T<sub>j</sub> <rightarrow> T<sub>k</sub></$> exists in
the precedence graph
<itemize>
<item> then <$>T<sub>j</sub></$> must appear before <$>T<sub>k</sub></$> in any serial schedule
</itemize>
Implication: if the precedence graph has cycles, then <$>S</$> can't be serialized.
<p>
Thus, the serializability test is reduced to cycle-detection
<p>
<small>(and there are cycle-detection algorithms available in many algorithms textbooks)</small>
</slide>

<slide>
<heading>Serializability Test Examples
Serializable schedule
	<~> <small>(with conflicting operations shown in <red>red</red>)</small>:
<program>
T1: R(A) <red>W(A)</red>      R(B)      <red>W(B)</red>
T2:           <red>R(A)</red>      W(A)      <red>R(B)</red> W(B)
</program>
Precedence graph for this schedule:
<diagram>Pic/xact/pg1.png
No cycles <$><Rightarrow></$> serializable
	<~><small>(as we already knew)</small>
</slide>

<slide>
<continued>
Consider this schedule:
<program>
T1: <red>R(A)</red>                W(A) R(B) <red>W(B)</red>
T2:      R(A) <red>W(A)</red> <red>R(B)</red>                W(B)
</program>
Precedence graph for this schedule:
<diagram>Pic/xact/pg2.png
Has a cycle <$><Rightarrow></$> not serializable
</slide>

<slide>
<continued>
Consider this 3-transaction schedule:
<program>
T1: R(A)R(C)<blue>W(A)</blue>    <red>W(C)</red>
T2:             R(B)    <blue>R(A)</blue>    <green>W(B)</green>        W(A)
T3:                         <red>R(C)</red>    <green>R(B)</green>W(C)    W(B)
</program>
Precedence graph for this schedule:
<diagram>Pic/xact/pg3.png
No cycles <$><Rightarrow></$> serializable
</slide>

<slide>
<continued>
Consider this 3-transaction schedule:
<program>
T1: R(A)                <blue>W(A)</blue>        <red>R(C)</red>    W(C)
T2:     R(B)    <green>W(B)</green>            <blue>R(A)</blue>    W(A)
T3:         R(C)    <red>W(C)</red>    <green>R(B)</green>                W(B)
</program>
Precedence graph for this schedule:
<diagram>Pic/xact/pg4.png
Has a cycle <$><Rightarrow></$> not serializable
</slide>

<slide>
<heading>Concurrency Control
Having serializability tests is useful theoretically, but they do not
provide a practical tool for organising schedules.
<p>
Why not practical?
<itemize>
<item> the # possible schedules for <$>n</$> transactions is <$>O(n!)</$>
<item> the cost of testing for serializability via graphs is <$>O(n<sup>2</sup>)</$>
</itemize>
What is required are methods
<itemize>
<item> that can be applied to each transaction individually
<item> which guarantee that any combination of transactions is serializable
</itemize>
</slide>

<slide>
<continued>
Approaches to ensuring AC<navy>I</navy>D transactions:
<itemize>
<item> lock-based
<p>
<small>Synchronise transaction execution via locks on some portion 
of the database.</small>
<item> version-based
<p>
<small>Allow multiple consistent versions of the data to exist, and
allow each transaction exclusive access to one version.</small>
<item> timestamp-based
<p>
<small>Organise transaction execution in advance by assigning timestamps to
operations.</small>
<item> validation-based <~> <small>(optimistic concurrency control)</small>
<p>
<small>Exploit typical execution-sequence properties of transactions to determine safety dynamically.</small>
</itemize>
</slide>

<slide>
<heading>Lock-based Concurrency Control
Synchronise access to shared data items via following rules:
<itemize>
<item> before reading <$>X</$>, get shared (read) lock on <$>X</$>
<item> before writing <$>X</$>, get exclusive (write) lock on <$>X</$>
<item> an attempt to get a shared lock on <$>X</$> is blocked
	if another transaction already has exclusive lock on <$>X</$>
<item> an attempt to get an exclusive lock on <$>X</$> is blocked
	if another transaction has any kind of lock on <$>X</$>
</itemize>
These rules alone do not guarantee serializability.
</slide>

<slide>
<heading>Two-Phase Locking
To guarantee serializability, we require an additional constraint
on how locks are applied:
<itemize>
<item> no transaction can request a lock after it has released one of its locks
</itemize>
Each transaction is then structured as:
<itemize>
<item> <em>growing</em> phase where locks are acquired
<item> <em>action</em> phase where <q>real work</q> is done
<item> <em>shrinking</em> phase where locks are released
</itemize>
</slide>

<slide>
<heading>Problems with Locking
Appropriate locking can guarantee correctness.
<p>
However, it also introduces potential undesirable effects:
<itemize>
<item> deadlock
<p>
<small>No transactions can proceed; each waiting on lock held by another.</small>
<item> starvation
<p>
<small>One transaction is permanently <q>frozen out</q> of access to data.</small>
<item> reduced performance
<p>
<small>Locking introduces delays while waiting for locks to be released.</small>
</itemize>
</slide>

<slide>
<heading>Deadlock
<p>
Deadlock occurs when two transactions are waiting
for a lock on an item held by the other.
<p>
Example:
<program>
T1              T2
--------------  ---------------
write_lock(X)
read(X)
                write_lock(Y)
                read(Y)
write_lock(Y)
<red>waiting for Y</red>   write_lock(X)
<red>waiting for Y</red>   <red>waiting for X</red>
</program>
</slide>

<slide>
<continued>
Handling deadlock involves forcing a transaction to <q>back off</q>.
<itemize>
<item> select a process to <q>back off</q>
<small>
<itemize>
<item> choose on basis of how far transaction has progressed, # locks held, ...
</itemize>
</small>
<item> roll back the selected process
<small>
<itemize>
<item> how far does this it need to be rolled back? (less roll-back is better)
</itemize>
</small>
<item> prevent starvation
<small>
<itemize>
<item> need methods to ensure that same transaction isn't always chosen
</itemize> 
</small>
</itemize>
</slide>

<slide>
<heading>Locking and Starvation
<em>Starvation</em> occurs when one transaction
<itemize>
<item> waits on a lock indefinitely
<item> while other transactions continue normally
</itemize>
Whether it occurs depends on the lock wait/release strategy.
<p>
Multiple locks <$><Rightarrow></$> need to decide which to release first.
<p>
Solutions:
<itemize>
<item> implement a fair wait/release strategy
	<small>(e.g. first-come-first-served)</small>
<item> use deadlock prevention schemes, such as <q>wait-die</q>
</itemize>
</slide>

<slide>
<heading>Locking and Performance
Locking typically reduces concurrency <$><Rightarrow></$> reduces throughput.
<p>
Granularity of locking can impact performance:
<p>
<green><b>+</b></green>
lock a small item <$><Rightarrow></$> more of database accessible
<p>
<green><b>+</b></green>
lock a small item <$><Rightarrow></$> quick update <$><Rightarrow></$> quick lock release
<p>
<red><b>-</b></red>
lock small items <$><Rightarrow></$> more locks <$><Rightarrow></$> more lock management
<p>
Granularity levels: field, row (tuple), table, whole database
<p>
Multiple lock-granularities give best scope for optimising performance.
</slide>

<slide>
<heading>Multi-version Concurrency Control
One approach to reducing the requirement for locks is to
<itemize>
<item> provide multiple (consistent) versions of the database
<item> give each transaction access to an <q>appropriate</q> version <br>
	<small>(i.e. a version that will mantain the serializability of the transaction)</small>
</itemize>
This approach is called <em>multi-version concurrency control</em> <small>(MVCC)</small>.
<p>
The primary difference between MVCC and standard locking models:
<itemize>
<item> read locks do not conflict with write locks, so that
<item> reading never blocks writing, and writing never blocks reading
</itemize>
</slide>

<slide>
<heading>MVCC and Transactions
Database systems using MVCC ensure
<itemize>
<item> statement-level read consistency <br>
	<small>(i.e. once an SQL SELECT statement starts, its view of the data is <q>frozen</q>)</small>
<item> readers do not wait for writers or other readers of the same data
<item> writers do not wait for readers of the same data
<item> writers only wait for other writers if they attempt to update
	 identical rows in concurrent transactions 
</itemize>
With this behaviour:
<itemize>
<item> a SELECT statement sees a consistent view of the database
<item> but it may not see the <q>current</q> view of the database
<p>
<small>
E.g. <$>T1</$> does a select and then concurrent <$>T2</$> deletes some of <$>T1</$>'s selected tuples
</small>
</itemize>
</slide>

<slide>
<heading>PostgreSQL and MVCC
PostgreSQL uses MVCC to reduce locking requirements.
<p>
Consequences:
<itemize>
<item> several versions of each tuple may exist <$><Rightarrow></$> uses more storage
<item> each transaction needs to check each tuple's <em>visibility</em>
<item> periodically, clean up <q>old</q> tuples <~> (<@>vacuum</@>)
</itemize>
An <q>old</q> tuple is one that is no longer visible to any transaction.
<p>
Concurrency control is still needed (via implicit locking):
<itemize>
<item> amount of locking is determined by user-chosen <em>isolation level</em>
<item> the system then applies appropriate locking automatically
</itemize>
</slide>

<slide>
<continued>
A transaction sees a consistent view of the database, but it may
not see the <q>current</q> view of the database.
<p>
<small>
E.g. <$>T1</$> does a select and then concurrent <$>T2</$> deletes some of <$>T1</$>'s selected tuples
</small>
<p>
This is not a problem unless the transactions communicate
outside the database system.
<p>
For applications that require that every transaction accesses the
current consistent version of the data, explicit locking must be used.
</slide>

<slide>
<heading>Concurrency Control in SQL
Transactions in SQL are specified by
<itemize>
<item> <@@>BEGIN</@@> ... start a transaction
<item> <@@>COMMIT</@@> ... successfully complete a transaction
<item> <@@>ROLLBACK</@@> ... undo changes made by transaction + abort
</itemize>
In PostgreSQL, other actions that cause rollback:
<itemize>
<item> <b>raise exception</b> during execution of a function
<item> returning null from a <b>before</b> trigger
</itemize>
</slide>

<slide>
<continued>
More fine-grained control of <q>undo</q> via savepoints:
<itemize>
<item> <@@>SAVEPOINT</@@> ... marks point in transaction
<item> <@@>ROLLBACK TO SAVEPOINT</@@> ... undo changes, continue transaction
</itemize>
Example:
<program>
begin;
  insert into numbersTable values (1);
  <blue>savepoint my_savepoint;</blue>
  insert into numbersTable values (2);
  <red>rollback to savepoint my_savepoint;</red>
  insert into numbersTable values (3);
commit;
</program>
will insert 1 and 3 into the table, but not 2.
</slide>

<slide>
<continued>
SQL standard defines four levels of <em>transaction isolation</em>.
<itemize>
<item> <em>serializable</em> - strongest isolation, most locking
<item> <em>repeatable read</em>
<item> <em>read committed</em>
<item> <em>read uncommitted</em> - weakest isolation, less locking
</itemize>
The weakest level allows dirty reads, phantom reads, etc.
<p>
<small>
PostgreSQL implements:
repeatable-read = serializable,
read-uncommitted = read-committed
</small>
</slide>

<slide>
<continued>
Using the serializable isolation level, a <@>select</@>:
<itemize>
<item> sees only data committed before the transaction began
<item> never sees changes made by concurrent transactions 
</itemize>
Using the serializable isolation level, an update fails:
<itemize>
<item> if it tries to modify an <q>active</q> data item <br>
<small>(active = affected by some other transaction, either committed or uncommitted)</small>
</itemize>
The transaction containing the failed update will rollback and re-start.
</slide>

<slide>
<continued>
Explicit control of concurrent access is available, e.g.
<p>
Table-level locking: <@@>LOCK TABLE</@@>
<itemize>
<item> various kinds of shared/exclusive locks are available
<itemize>
<sitem> <b>access share</b> allows others to read, and some writes
<sitem> <b>exclusive</b> allows others to read, but not to write
<sitem> <b>access exclusive</b> blocks all other access to table
</itemize>
<item> SQL commands automatically acquire appropriate locks
<itemize>
<sitem> e.g. <@@>ALTER TABLE</@@> acquires an <b>access exclusive</b> lock
</itemize>
</itemize>
<p>
Row-level locking: <@@>SELECT FOR UPDATE</@@>, <@@>UPDATE</@@>, <@@>DELETE</@@>
<itemize>
<item> allows others to read, but blocks write on selected rows
</itemize>
All locks are released at end of transaction <small>(no explicit unlock)</small>
</slide>

<slide>
<heading>PostgreSQL, Transactions, Concurrency
For more details on PostgreSQL's handling of these:
<itemize>
<item> Chapter 12: Concurrency Control
<item> SQL commands: BEGIN, COMMIT, ROLLBACK, LOCK, etc.
</itemize>
</slide>
